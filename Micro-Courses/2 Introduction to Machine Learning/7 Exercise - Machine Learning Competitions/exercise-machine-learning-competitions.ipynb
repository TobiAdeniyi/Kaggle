{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[Introduction to Machine Learning Home Page](https://www.kaggle.com/learn/intro-to-machine-learning)**\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "Machine learning competitions are a great way to improve your data science skills and measure your progress. \n",
    "\n",
    "In this exercise, you will create and submit predictions for a Kaggle competition. You can then improve your model (e.g. by adding features) to improve and see how you stack up to others taking this micro-course.\n",
    "\n",
    "The steps in this notebook are:\n",
    "1. Build a Random Forest model with all of your data (**X** and **y**)\n",
    "2. Read in the \"test\" data, which doesn't include values for the target.  Predict home values in the test data with your Random Forest model.\n",
    "3. Submit those predictions to the competition and see your score.\n",
    "4. Optionally, come back to see if you can improve your model by adding features or changing your model. Then you can resubmit to see how that stacks up on the competition leaderboard."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recap\n",
    "Here's the code you've written so far. Start by running it again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation MAE when not specifying max_leaf_nodes: 29,653\n",
      "Validation MAE for best value of max_leaf_nodes: 27,283\n",
      "Validation MAE for Random Forest Model: 21,857\n"
     ]
    }
   ],
   "source": [
    "# Code you have previously used to load data\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# Set up code checking\n",
    "import os\n",
    "if not os.path.exists(\"../input/train.csv\"):\n",
    "    os.symlink(\"../input/home-data-for-ml-course/train.csv\", \"../input/train.csv\")  \n",
    "    os.symlink(\"../input/home-data-for-ml-course/test.csv\", \"../input/test.csv\") \n",
    "from learntools.core import binder\n",
    "binder.bind(globals())\n",
    "from learntools.machine_learning.ex7 import *\n",
    "\n",
    "# Path of the file to read. We changed the directory structure to simplify submitting to a competition\n",
    "iowa_file_path = '../input/train.csv'\n",
    "\n",
    "home_data = pd.read_csv(iowa_file_path)\n",
    "# Create target object and call it y\n",
    "y = home_data.SalePrice\n",
    "# Create X\n",
    "features = ['LotArea', 'YearBuilt', '1stFlrSF', '2ndFlrSF', 'FullBath', 'BedroomAbvGr', 'TotRmsAbvGrd']\n",
    "X = home_data[features]\n",
    "\n",
    "# Split into validation and training data\n",
    "train_X, val_X, train_y, val_y = train_test_split(X, y, random_state=1)\n",
    "\n",
    "# Specify Model\n",
    "iowa_model = DecisionTreeRegressor(random_state=1)\n",
    "# Fit Model\n",
    "iowa_model.fit(train_X, train_y)\n",
    "\n",
    "# Make validation predictions and calculate mean absolute error\n",
    "val_predictions = iowa_model.predict(val_X)\n",
    "val_mae = mean_absolute_error(val_predictions, val_y)\n",
    "print(\"Validation MAE when not specifying max_leaf_nodes: {:,.0f}\".format(val_mae))\n",
    "\n",
    "# Using best value for max_leaf_nodes\n",
    "iowa_model = DecisionTreeRegressor(max_leaf_nodes=100, random_state=1)\n",
    "iowa_model.fit(train_X, train_y)\n",
    "val_predictions = iowa_model.predict(val_X)\n",
    "val_mae = mean_absolute_error(val_predictions, val_y)\n",
    "print(\"Validation MAE for best value of max_leaf_nodes: {:,.0f}\".format(val_mae))\n",
    "\n",
    "# Define the model. Set random_state to 1\n",
    "rf_model = RandomForestRegressor(random_state=1)\n",
    "rf_model.fit(train_X, train_y)\n",
    "rf_val_predictions = rf_model.predict(val_X)\n",
    "rf_val_mae = mean_absolute_error(rf_val_predictions, val_y)\n",
    "\n",
    "print(\"Validation MAE for Random Forest Model: {:,.0f}\".format(rf_val_mae))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a Model For the Competition\n",
    "\n",
    "Build a Random Forest model and train it on all of **X** and **y**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max leaf nodes: 5  \t\t Mean Absolute Error:  31441\n",
      "Max leaf nodes: 50  \t\t Mean Absolute Error:  22929\n",
      "Max leaf nodes: 500  \t\t Mean Absolute Error:  22143\n",
      "Max leaf nodes: 5000  \t\t Mean Absolute Error:  22140\n",
      "Max leaf nodes: 50000  \t\t Mean Absolute Error:  22140\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
       "                      max_depth=None, max_features='auto', max_leaf_nodes=5000,\n",
       "                      max_samples=None, min_impurity_decrease=0.0,\n",
       "                      min_impurity_split=None, min_samples_leaf=1,\n",
       "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                      n_estimators=100, n_jobs=None, oob_score=False,\n",
       "                      random_state=1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def rf_get_mae(max_leaf_nodes, train_X, val_X, train_y, val_y):\n",
    "    model = RandomForestRegressor(max_leaf_nodes = max_leaf_nodes, random_state = 0)\n",
    "    model.fit(train_X, train_y)\n",
    "    preds_val = model.predict(val_X)\n",
    "    mae = mean_absolute_error(val_y, preds_val)\n",
    "    return(mae)\n",
    "\n",
    "for max_leaf_nodes in [5, 50, 500, 5000, 50000]:\n",
    "    my_mae = rf_get_mae(max_leaf_nodes, train_X, val_X, train_y, val_y)\n",
    "    print(\"Max leaf nodes: %d  \\t\\t Mean Absolute Error:  %d\" %(max_leaf_nodes, my_mae))\n",
    "\n",
    "# To improve accuracy, create a new Random Forest model which you will train on all training data\n",
    "rf_model_on_full_data = RandomForestRegressor(random_state = 1)\n",
    "rf_model1_on_full_data = RandomForestRegressor(max_leaf_nodes = 5000, random_state = 1)\n",
    "# fit rf_model_on_full_data on all data from the training data\n",
    "rf_model_on_full_data.fit(X, y)\n",
    "rf_model1_on_full_data.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Predictions\n",
    "Read the file of \"test\" data. And apply your model to make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>...</th>\n",
       "      <th>GarageArea</th>\n",
       "      <th>WoodDeckSF</th>\n",
       "      <th>OpenPorchSF</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1459.000000</td>\n",
       "      <td>1459.000000</td>\n",
       "      <td>1232.000000</td>\n",
       "      <td>1459.000000</td>\n",
       "      <td>1459.000000</td>\n",
       "      <td>1459.000000</td>\n",
       "      <td>1459.000000</td>\n",
       "      <td>1459.000000</td>\n",
       "      <td>1444.000000</td>\n",
       "      <td>1458.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1458.000000</td>\n",
       "      <td>1459.000000</td>\n",
       "      <td>1459.000000</td>\n",
       "      <td>1459.000000</td>\n",
       "      <td>1459.000000</td>\n",
       "      <td>1459.000000</td>\n",
       "      <td>1459.000000</td>\n",
       "      <td>1459.000000</td>\n",
       "      <td>1459.000000</td>\n",
       "      <td>1459.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2190.000000</td>\n",
       "      <td>57.378341</td>\n",
       "      <td>68.580357</td>\n",
       "      <td>9819.161069</td>\n",
       "      <td>6.078821</td>\n",
       "      <td>5.553804</td>\n",
       "      <td>1971.357779</td>\n",
       "      <td>1983.662783</td>\n",
       "      <td>100.709141</td>\n",
       "      <td>439.203704</td>\n",
       "      <td>...</td>\n",
       "      <td>472.768861</td>\n",
       "      <td>93.174777</td>\n",
       "      <td>48.313914</td>\n",
       "      <td>24.243317</td>\n",
       "      <td>1.794380</td>\n",
       "      <td>17.064428</td>\n",
       "      <td>1.744345</td>\n",
       "      <td>58.167923</td>\n",
       "      <td>6.104181</td>\n",
       "      <td>2007.769705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>421.321334</td>\n",
       "      <td>42.746880</td>\n",
       "      <td>22.376841</td>\n",
       "      <td>4955.517327</td>\n",
       "      <td>1.436812</td>\n",
       "      <td>1.113740</td>\n",
       "      <td>30.390071</td>\n",
       "      <td>21.130467</td>\n",
       "      <td>177.625900</td>\n",
       "      <td>455.268042</td>\n",
       "      <td>...</td>\n",
       "      <td>217.048611</td>\n",
       "      <td>127.744882</td>\n",
       "      <td>68.883364</td>\n",
       "      <td>67.227765</td>\n",
       "      <td>20.207842</td>\n",
       "      <td>56.609763</td>\n",
       "      <td>30.491646</td>\n",
       "      <td>630.806978</td>\n",
       "      <td>2.722432</td>\n",
       "      <td>1.301740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1461.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>1470.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1879.000000</td>\n",
       "      <td>1950.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2006.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1825.500000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>7391.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1953.000000</td>\n",
       "      <td>1963.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>318.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2007.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2190.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>9399.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1973.000000</td>\n",
       "      <td>1992.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>350.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>480.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2008.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2554.500000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>11517.500000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2001.000000</td>\n",
       "      <td>2004.000000</td>\n",
       "      <td>164.000000</td>\n",
       "      <td>753.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>576.000000</td>\n",
       "      <td>168.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>2009.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2919.000000</td>\n",
       "      <td>190.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>56600.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>2010.000000</td>\n",
       "      <td>2010.000000</td>\n",
       "      <td>1290.000000</td>\n",
       "      <td>4010.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1488.000000</td>\n",
       "      <td>1424.000000</td>\n",
       "      <td>742.000000</td>\n",
       "      <td>1012.000000</td>\n",
       "      <td>360.000000</td>\n",
       "      <td>576.000000</td>\n",
       "      <td>800.000000</td>\n",
       "      <td>17000.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>2010.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Id   MSSubClass  LotFrontage       LotArea  OverallQual  \\\n",
       "count  1459.000000  1459.000000  1232.000000   1459.000000  1459.000000   \n",
       "mean   2190.000000    57.378341    68.580357   9819.161069     6.078821   \n",
       "std     421.321334    42.746880    22.376841   4955.517327     1.436812   \n",
       "min    1461.000000    20.000000    21.000000   1470.000000     1.000000   \n",
       "25%    1825.500000    20.000000    58.000000   7391.000000     5.000000   \n",
       "50%    2190.000000    50.000000    67.000000   9399.000000     6.000000   \n",
       "75%    2554.500000    70.000000    80.000000  11517.500000     7.000000   \n",
       "max    2919.000000   190.000000   200.000000  56600.000000    10.000000   \n",
       "\n",
       "       OverallCond    YearBuilt  YearRemodAdd   MasVnrArea   BsmtFinSF1  ...  \\\n",
       "count  1459.000000  1459.000000   1459.000000  1444.000000  1458.000000  ...   \n",
       "mean      5.553804  1971.357779   1983.662783   100.709141   439.203704  ...   \n",
       "std       1.113740    30.390071     21.130467   177.625900   455.268042  ...   \n",
       "min       1.000000  1879.000000   1950.000000     0.000000     0.000000  ...   \n",
       "25%       5.000000  1953.000000   1963.000000     0.000000     0.000000  ...   \n",
       "50%       5.000000  1973.000000   1992.000000     0.000000   350.500000  ...   \n",
       "75%       6.000000  2001.000000   2004.000000   164.000000   753.500000  ...   \n",
       "max       9.000000  2010.000000   2010.000000  1290.000000  4010.000000  ...   \n",
       "\n",
       "        GarageArea   WoodDeckSF  OpenPorchSF  EnclosedPorch    3SsnPorch  \\\n",
       "count  1458.000000  1459.000000  1459.000000    1459.000000  1459.000000   \n",
       "mean    472.768861    93.174777    48.313914      24.243317     1.794380   \n",
       "std     217.048611   127.744882    68.883364      67.227765    20.207842   \n",
       "min       0.000000     0.000000     0.000000       0.000000     0.000000   \n",
       "25%     318.000000     0.000000     0.000000       0.000000     0.000000   \n",
       "50%     480.000000     0.000000    28.000000       0.000000     0.000000   \n",
       "75%     576.000000   168.000000    72.000000       0.000000     0.000000   \n",
       "max    1488.000000  1424.000000   742.000000    1012.000000   360.000000   \n",
       "\n",
       "       ScreenPorch     PoolArea       MiscVal       MoSold       YrSold  \n",
       "count  1459.000000  1459.000000   1459.000000  1459.000000  1459.000000  \n",
       "mean     17.064428     1.744345     58.167923     6.104181  2007.769705  \n",
       "std      56.609763    30.491646    630.806978     2.722432     1.301740  \n",
       "min       0.000000     0.000000      0.000000     1.000000  2006.000000  \n",
       "25%       0.000000     0.000000      0.000000     4.000000  2007.000000  \n",
       "50%       0.000000     0.000000      0.000000     6.000000  2008.000000  \n",
       "75%       0.000000     0.000000      0.000000     8.000000  2009.000000  \n",
       "max     576.000000   800.000000  17000.000000    12.000000  2010.000000  \n",
       "\n",
       "[8 rows x 37 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# path to file you will use for predictions\n",
    "test_data_path = '../input/test.csv'\n",
    "\n",
    "# read test data file using pandas\n",
    "test_data = pd.read_csv(test_data_path)\n",
    "test_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   LotArea  YearBuilt  1stFlrSF  2ndFlrSF  FullBath  BedroomAbvGr  \\\n",
      "0    11622       1961       896         0         1             2   \n",
      "1    14267       1958      1329         0         1             3   \n",
      "2    13830       1997       928       701         2             3   \n",
      "3     9978       1998       926       678         2             3   \n",
      "4     5005       1992      1280         0         2             2   \n",
      "\n",
      "   TotRmsAbvGrd  \n",
      "0             5  \n",
      "1             6  \n",
      "2             6  \n",
      "3             7  \n",
      "4             5  \n",
      "[123214.58 156674.5  183694.   178162.   188362.29]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# create test_X which comes from test_data but includes only the columns you used for prediction.\n",
    "# The list of columns is stored in a variable called features\n",
    "test_X = test_data[features]\n",
    "print(test_X.head())\n",
    "\n",
    "# make predictions which we will submit. \n",
    "test_preds = rf_model1_on_full_data.predict(test_X)\n",
    "print(rf_model1_on_full_data.predict(test_X.head()))\n",
    "\n",
    "# The lines below shows how to save predictions in format used for competition scoring\n",
    "# Just uncomment them.\n",
    "\n",
    "output = pd.DataFrame({'Id': test_data.Id,\n",
    "                       'SalePrice': test_preds})\n",
    "\n",
    "output.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before submitting, run a check to make sure your `test_preds` have the right format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"outcomeType\": 1, \"valueTowardsCompletion\": 1.0, \"interactionType\": 1, \"questionType\": 2, \"questionId\": \"1_CheckSubmittablePreds\", \"learnToolsVersion\": \"0.3.4\", \"failureMessage\": \"\", \"exceptionClass\": \"\", \"trace\": \"\"}}, \"*\")"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<span style=\"color:#33cc33\">Correct</span>"
      ],
      "text/plain": [
       "Correct"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check your answer\n",
    "step_1.check()\n",
    "# step_1.solution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Your Work\n",
    "\n",
    "To test your results, you'll need to join the competition (if you haven't already).  So open a new window by clicking on [this link](https://www.kaggle.com/c/home-data-for-ml-course).  Then click on the **Join Competition** button.\n",
    "\n",
    "![join competition image](https://i.imgur.com/wLmFtH3.png)\n",
    "\n",
    "Next, follow the instructions below:\n",
    "1. Begin by clicking on the blue **Save Version** button in the top right corner of this window.  This will generate a pop-up window.  \n",
    "2. Ensure that the **Save and Run All** option is selected, and then click on the blue **Save** button.\n",
    "3. This generates a window in the bottom left corner of the notebook.  After it has finished running, click on the number to the right of the **Save Version** button.  This pulls up a list of versions on the right of the screen.  Click on the ellipsis **(...)** to the right of the most recent version, and select **Open in Viewer**.  This brings you into view mode of the same page. You will need to scroll down to get back to these instructions.\n",
    "4. Click on the **Output** tab on the right of the screen.  Then, click on the **Submit to Competition** button to submit your results to the leaderboard.\n",
    "\n",
    "You have now successfully submitted to the competition!\n",
    "\n",
    "If you want to keep working to improve your performance, select the blue **Edit** button in the top right of the screen. Then you can change your code and repeat the process. There's a lot of room to improve, and you will climb up the leaderboard as you work.\n",
    "\n",
    "\n",
    "# Continuing Your Progress\n",
    "There are many ways to improve your model, and **experimenting is a great way to learn at this point.**\n",
    "\n",
    "The best way to improve your model is to add features.  Look at the list of columns and think about what might affect home prices.  Some features will cause errors because of issues like missing values or non-numeric data types. \n",
    "\n",
    "The **[Intermediate Machine Learning](https://www.kaggle.com/learn/intermediate-machine-learning)** micro-course will teach you how to handle these types of features. You will also learn to use **xgboost**, a technique giving even better accuracy than Random Forest.\n",
    "\n",
    "\n",
    "# Other Micro-Courses\n",
    "The **[Pandas](https://kaggle.com/Learn/Pandas)** micro-course will give you the data manipulation skills to quickly go from conceptual idea to implementation in your data science projects. \n",
    "\n",
    "You are also ready for the **[Deep Learning](https://kaggle.com/Learn/Deep-Learning)** micro-course, where you will build models with better-than-human level performance at computer vision tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**[Introduction to Machine Learning Home Page](https://www.kaggle.com/learn/intro-to-machine-learning)**\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "*Have questions or comments? Visit the [Learn Discussion forum](https://www.kaggle.com/learn-forum) to chat with other Learners.*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
